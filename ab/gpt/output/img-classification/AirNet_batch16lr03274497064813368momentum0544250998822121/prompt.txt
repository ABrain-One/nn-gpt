**Objective**: Redesign the CNN architecture in `Net(nn.Module)` to enhance classification performance with structural diversity and modern deep learning components.

**Architectural Requirements**:
1. You must make meaningful changes to the architecture (e.g., reordering, adding, or removing layers). Do NOT just tweak numeric parameters.
2. Replace standard Conv2d blocks with more advanced alternatives such as:
   - Depthwise separable convolutions
   - Grouped convolutions
   - Attention blocks (e.g., Squeeze-and-Excitation)
   - Advanced activations like `SiLU`, `GELU`
   - Residual connections or bottlenecks
3. Avoid using Dropout or any regularization except `BatchNorm2d`.
4. Redesign the convolutional backbone so the layer structure differs from the original.
5. The in_shape and out_shape of the model must be different from the original model to reflect a true architectural overhaul.

**Hyperparameter Rules**:
- Only use `prm['lr']` and `prm['momentum']`. Do not use any other hyperparameters (e.g., dropout rate, weight decay, etc.).
- Include a method `def supported_hyperparameters()` that returns `['lr', 'momentum']`.

**Output Requirements**:
- Return a complete and valid Python class that can compile and train the model.
- Ensure the new architecture is substantially different from the original model (no repetition of the same blocks).
- Do not include any `Dropout`, and use only modules that improve learning capacity.
- **Do NOT output any auxiliary text—no `**Notes**`, no “Modified Code” label—just the plain code block.**

**Original Code to Modify:**
```
import torch
import torch.nn as nn


def supported_hyperparameters():
    return {'lr', 'momentum'}


class AirInitBlock(nn.Module):
    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.layers = nn.Sequential(
            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True)
        )

    def forward(self, x):
        return self.layers(x)


class AirUnit(nn.Module):
    def __init__(self, in_channels, out_channels, stride):
        super().__init__()
        self.layers = nn.Sequential(
            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(out_channels)
        )
        self.downsample = (
            nn.Sequential(
                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),
                nn.BatchNorm2d(out_channels)
            ) if stride != 1 or in_channels != out_channels else nn.Identity()
        )
        self.relu = nn.ReLU(inplace=True)

    def forward(self, x):
        residual = self.downsample(x)
        x = self.layers(x)
        return self.relu(x + residual)


class Net(nn.Module):
    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:
        super().__init__()
        self.device = device
        self.in_channels = in_shape[1]
        self.image_size = in_shape[2]
        self.num_classes = out_shape[0]
        self.learning_rate = prm['lr']
        self.momentum = prm['momentum']

        channels = [64, 128, 256, 512]
        init_block_channels = 64

        self.features = self.build_features(init_block_channels, channels)
        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
        self.classifier = nn.Linear(channels[-1], self.num_classes)

    def build_features(self, init_block_channels, channels):
        layers = [AirInitBlock(self.in_channels, init_block_channels)]
        for i, out_channels in enumerate(channels):
            layers.append(AirUnit(
                in_channels=init_block_channels if i == 0 else channels[i - 1],
                out_channels=out_channels,
                stride=1 if i == 0 else 2))
        return nn.Sequential(*layers)

    def forward(self, x):
        x = self.features(x)
        x = self.avgpool(x)
        x = torch.flatten(x, 1)
        return self.classifier(x)

    def train_setup(self, prm):
        self.to(self.device)
        self.criteria = nn.CrossEntropyLoss().to(self.device)
        self.optimizer = torch.optim.SGD(
            self.parameters(),
            lr=self.learning_rate,
            momentum=self.momentum
        )

    def learn(self, train_data):
        self.train()
        for inputs, labels in train_data:
            inputs, labels = inputs.to(self.device), labels.to(self.device)
            self.optimizer.zero_grad()
            outputs = self(inputs)
            loss = self.criteria(outputs, labels)
            loss.backward()
            nn.utils.clip_grad_norm_(self.parameters(), 3)
            self.optimizer.step()

```